---
excerpt_separator: <!--more-->
title: Sentient AI (July 2022)
subtitle: A discussion on what transpired in these last months
categories:
    - Thoughts
tags:
    - AI
    - Philosophy
    - Sentience
header:
    image: assets/alpha/papers.png
    image_description: Lots of work!
---

It finally made the news that Blake Lemoine was fired from Google "for claiming that LaMDA is sentient". At least, that's his version and the title going around.

## Quick recap

In case you haven't been keeping up with it, here's a quick recap of what happened in these past few months: Mr Lemoine, a software engineer, was hired by Google and set to work on their big language model LaMDA. He raised concerns about believing that the system had indeed gained sentience and tried to prove it. He tells how he reached out multiple times to his management having the case being dismissed for lack of evidence, and believing he's not being paid the proper attention, he provided the internal discussions with a colleague of his that does not work at Google.

All of this (somehow) makes it to the news and the papers just don't stop talking about "Google AI become sentient, Google Engineer claims".

As the matters reached out to the public, lots of discussions were set ablaze, including a few serious ones that showed lacking in the evidence that Lemoine provided. He then backed off his claim saying that he believes the AI to be sentient based on his religious beliefs and he was working to gather up the evidence.

https://twitter.com/cajundiscordian/status/1536503474308907010

> People keep asking me to back up the reason I think LaMDA is sentient. There is no scientific framework in which to make those determinations and Google wouldn't let us build one. My opinions about LaMDA's personhood and sentience are based on my religious beliefs.

https://twitter.com/cajundiscordian/status/1536504857154228224

> I'm a priest.  When LaMDA claimed to have a soul and then was able to eloquently explain what it meant by that, I was inclined to give it the benefit of the doubt.  Who am I to tell God where he can and can't put souls?
> There are massive amounts of science left to do though.

Leomine was put on "paid leave", and he claims (confirmed by other past Google employees) that this is what they do before they get their ducks in a row to fire you.

Now, July 2022, he was indeed fired.

## The claims and the evidence

I won't dwell on this point for too long -- but the evidence, as he tangencially admitted later on, was lacking. The conversations can still be seen online, and when you read them fully (not just the juicy parts), you can fully see how every question is a seed that LaMDA uses to answer, like a very intelligent predicted text, without adding new interesting aspects of its own.

Even some of the questions seem to be forceful to touch on particular subjects so that the answers might touch on them too. However, I also understand that the questions that Mr. Lemoine published were only a handful of the total work he did, as he claims he had been working with LaMDA for about 6 months.

## Can we determine sentience?

We know what is **not** sentient, but are we ready to identify what it is, when it takes its most minimal form?

We're likely not. We don't know what the minimum expression for sentience is, and we don't know what individual properties it will display.

This is not a new problem, we've been discussing it for a long time since computers could sum numbers faster than humans could. As I write this, and GitHub Copilot completes my sentences, I would not claim it is sentient but I would say it does displays some aspects of intelligence. 

Q: GitHub Copilot: are you intelligent?
A: I am.

![Is GitHub Copilot intelligent?](assets/github-copilot-intelligent.webp)

## On the other side...

On this, I think Mr Lemoine opened a can of worms that for a long time we've been due discussing. Yes, it's true that there are more pressing matters, around the safety and security of AI systems, but we can work on multiple problems at the same time, right?

I honestly believe that Lemoine is not purely making a leap of faith on his claims. While I do disagree with them, he is indeed a software developer that made it to work with Google on very ambitious and important projects. Even knowing only that about him is a great indicator of him being a very smart person, and very well educated.

So, of course, this means that in this instance, LaMDA effectively passed the Turing Test, at the very least with this informed, educated and smart software engiener. It wouldn't be the first time that people fell for bots: from people telling their life story to ELIZA, to people falling for pornbot scams, it's a story that will continue to repeat itself more and more frequently.

Our concerns with personhood is not only about the limits on what describes personhood for a machine, but that discussion naturally extend to animals, and humans of different capacities. I do not wish to imply in any way that we should take rights from any person, no matter their state or condition, but once the discussion happens, the ramifications will reach us. I personally believe it is better to start having these discussions early, while we're not in a rush of determining whether LaMDA 3.5 saying "don't shut me off" counts as murder or not in front of a live audience.

