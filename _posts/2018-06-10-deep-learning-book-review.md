---
layout: post
excerpt_separator: <!--more-->
status: publish
published: true
title: Deep Learning (book review)
author:
  display_name: Alpha
  login: Alpha
  email: alphagma@gmail.com
  url: http://www.alphasmanifesto.com/
author_login: Alpha
author_email: alphagma@gmail.com
author_url: http://www.alphasmanifesto.com/
wordpress_id: 6490
wordpress_url: https://blog.alphasmanifesto.com/?p=6490
date: '2018-06-10 12:43:23 +0000'
date_gmt: '2018-06-10 16:43:23 +0000'
categories:
- Books
- AI
tags:
- book
- artificial intelligence
- book review
- deep learning
- neural network
- research
- reference
---

![]({{ site.baseurl }}/assets/deep-learning.jpg)

I finally finished reading Deep Learning, by Ian Goodfellow, Yoshua Bengio and Aaron Courville. And as a wonderful as a book as it is, it wasn't an easy read, at all.

<!--more-->

I recently finished reading one of the recommendations that reached me, Deep Learning. This book can be found online and for free, in its [official web page](http://www.deeplearningbook.org/), and it is absolutely ones of the best literature reference books that you'll find for the Deep Learning state of the art. Of course, we're talking about Artificial Intelligence and its particular sub-area on multi-layer neural networks.

The book requires some undergraduate calculus and probability level knowledge to start and follow, but it gets very complicated really fast. This is because this book takes a mathematical approach to describing neural networks and processes. It gives a very detailed look at the implications of choosing a particular function over the other, the challenges of particular distributions, the challenges of optimizations and so on.

As such, while being very difficult to follow, it is also one of the best references that you'll find on the subject.

The book is filled with references to sources and papers that will go into detail explaining the claims being made on the book, even those that are still under debate. It also covers the progression of how a particular assumption (say, a choice of neural network architecture) becomes a particular problem of some other kind, allowing you to reframe the problem in other contexts. This is very rich.

Having said that, it is also very hard as a read. It required a huge amount of focus, as it wastes no time in moving from one point to the next. And still, having such a high density of information, it comprises full almost-800 pages of explanations!

My recommendation is: if you're looking to understand how Deep Learning works, this book is too advanced for you. If you are already intimate with the subject and need to view at it from the mathematical foundations, you will find this book most appropriate. If you are diving into research and are planning to expand on the fringe of what we already know, this book is definitely for you.
